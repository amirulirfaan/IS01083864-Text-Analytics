{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3f66d-f07b-4155-a456-86e7f8bc5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import string\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from autocorrect import Speller\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Initialize tools\n",
    "spell = Speller(lang='en')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"UNITENReview.csv\")\n",
    "\n",
    "# Display original data to identify issues\n",
    "print(\"Original Data:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumn names:\", df.columns.tolist())\n",
    "print(\"\\nData types:\", df.dtypes)\n",
    "print(\"\\nMissing values:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0710e8-019c-4205-8ec0-254eabf1de44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.12-py312",
   "language": "python",
   "name": "conda-env-anaconda-2025.12-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
